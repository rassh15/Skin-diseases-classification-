{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rassh/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(random_state=9)))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier(random_state=9)))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=100, random_state=9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To keep results\n",
    "results = []\n",
    "names = []\n",
    "scoring = \"accuracy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import feature vector and trained labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f_data = h5py.File('output/data.h5', 'r')\n",
    "h5f_label = h5py.File('output/labels.h5', 'r')\n",
    "\n",
    "features_d = h5f_data['dataset_1']\n",
    "labels_d = h5f_label['dataset_1']\n",
    "\n",
    "features = np.array(features_d)\n",
    "labels = np.array(labels_d)\n",
    "\n",
    "h5f_data.close()\n",
    "h5f_label.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (321, 62500)\n",
      "Labels shape: (321,)\n",
      "Training started...\n"
     ]
    }
   ],
   "source": [
    "# verify the shape of the feature vector and labels\n",
    "print (\"Features shape: {}\".format(features.shape))\n",
    "print (\"Labels shape: {}\".format(labels.shape))\n",
    "\n",
    "print (\"Training started...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training and testing data\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(np.array(features),\n",
    "                                                                  np.array(labels),\n",
    "                                                                  test_size=.10,\n",
    "                                                                  random_state=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test data splitted\n",
      "Train data  : (288, 62500)\n",
      "Test data   : (33, 62500)\n",
      "Train labels: (288,)\n",
      "Test labels : (33,)\n"
     ]
    }
   ],
   "source": [
    "print (\"Train and Test data splitted\")\n",
    "print (\"Train data  : {}\".format(trainData.shape))\n",
    "print (\"Test data   : {}\".format(testData.shape))\n",
    "print (\"Train labels: {}\".format(trainLabels.shape))\n",
    "print (\"Test labels : {}\".format(testLabels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter all the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB: 0.486946 (0.111215)\n",
      "SVM: 0.371921 (0.076150)\n",
      "KNN: 0.608744 (0.110002)\n",
      "CART: 0.542241 (0.068803)\n",
      "RF: 0.601232 (0.082756)\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    cv_results = cross_val_score(model, trainData, trainLabels, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "svc= SVC(random_state=9)\n",
    "knn = KNeighborsClassifier()\n",
    "dt = DecisionTreeClassifier(random_state=9)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = trainData\n",
    "test_features = testData\n",
    "training_target = trainLabels\n",
    "test_target = testLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB\n",
      "0.5277777777777778\n",
      "0.5757575757575758\n",
      "[[7 1 5]\n",
      " [3 6 5]\n",
      " [0 0 6]]\n"
     ]
    }
   ],
   "source": [
    "trained_model = nb.fit(training_features, training_target)\n",
    "trained_model.fit(training_features, training_target)\n",
    "predictions = trained_model.predict(test_features)      \n",
    "\n",
    "Train_Accuracy = accuracy_score(training_target, trained_model.predict(training_features))\n",
    "Test_Accuracy = accuracy_score(test_target, predictions)\n",
    "Confusion_Matrix = confusion_matrix(test_target, predictions)\n",
    "print('NB')\n",
    "print(Train_Accuracy)\n",
    "print(Test_Accuracy)\n",
    "print(Confusion_Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "0.3784722222222222\n",
      "0.21212121212121213\n",
      "[[ 1  0 12]\n",
      " [ 3  0 11]\n",
      " [ 0  0  6]]\n"
     ]
    }
   ],
   "source": [
    "#svc\n",
    "trained_model = svc.fit(training_features, training_target)\n",
    "trained_model.fit(training_features, training_target)\n",
    "predictions = trained_model.predict(test_features)      \n",
    "\n",
    "Train_Accuracy = accuracy_score(training_target, trained_model.predict(training_features))\n",
    "Test_Accuracy = accuracy_score(test_target, predictions)\n",
    "Confusion_Matrix = confusion_matrix(test_target, predictions)\n",
    "print('SVC')\n",
    "print(Train_Accuracy)\n",
    "print(Test_Accuracy)\n",
    "print(Confusion_Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "0.6805555555555556\n",
      "0.42424242424242425\n",
      "[[8 3 2]\n",
      " [8 3 3]\n",
      " [3 0 3]]\n"
     ]
    }
   ],
   "source": [
    "#knn\n",
    "trained_model = knn.fit(training_features, training_target)\n",
    "trained_model.fit(training_features, training_target)\n",
    "predictions = trained_model.predict(test_features)      \n",
    "\n",
    "Train_Accuracy = accuracy_score(training_target, trained_model.predict(training_features))\n",
    "Test_Accuracy = accuracy_score(test_target, predictions)\n",
    "Confusion_Matrix = confusion_matrix(test_target, predictions)\n",
    "print('KNN')\n",
    "print(Train_Accuracy)\n",
    "print(Test_Accuracy)\n",
    "print(Confusion_Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "1.0\n",
      "0.45454545454545453\n",
      "[[8 3 2]\n",
      " [5 4 5]\n",
      " [2 1 3]]\n"
     ]
    }
   ],
   "source": [
    "#dt\n",
    "trained_model = dt.fit(training_features, training_target)\n",
    "trained_model.fit(training_features, training_target)\n",
    "predictions = trained_model.predict(test_features)      \n",
    "\n",
    "Train_Accuracy = accuracy_score(training_target, trained_model.predict(training_features))\n",
    "Test_Accuracy = accuracy_score(test_target, predictions)\n",
    "Confusion_Matrix = confusion_matrix(test_target, predictions)\n",
    "print('Decision Tree')\n",
    "print(Train_Accuracy)\n",
    "print(Test_Accuracy)\n",
    "print(Confusion_Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randor Forest\n",
      "1.0\n",
      "0.5151515151515151\n",
      "[[8 3 2]\n",
      " [8 4 2]\n",
      " [1 0 5]]\n"
     ]
    }
   ],
   "source": [
    "#rf\n",
    "trained_model = rf.fit(training_features, training_target)\n",
    "trained_model.fit(training_features, training_target)\n",
    "predictions = trained_model.predict(test_features)      \n",
    "\n",
    "Train_Accuracy = accuracy_score(training_target, trained_model.predict(training_features))\n",
    "Test_Accuracy = accuracy_score(test_target, predictions)\n",
    "Confusion_Matrix = confusion_matrix(test_target, predictions)\n",
    "print('Randor Forest')\n",
    "print(Train_Accuracy)\n",
    "print(Test_Accuracy)\n",
    "print(Confusion_Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
