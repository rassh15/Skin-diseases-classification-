{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin diseases classfication using image processing and machine learnings technqiues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rassh/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skimage import color\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure\n",
    "import numpy as np\n",
    "import mahotas\n",
    "import cv2\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data path\n",
    "train_path = \"dataset/train\"\n",
    "\n",
    "# Fixes image size\n",
    "fixed_size = tuple((250, 250))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extacted using Histogram of oreinted gradiented "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def hog_ext(image):\n",
    "    img = color.rgb2gray(image)\n",
    "    fd, hog_image = hog(img, orientations=7, \n",
    "                        pixels_per_cell=(16, 16),cells_per_block=(1, 1), \n",
    "                        block_norm='L1', feature_vector=True, visualise=True)\n",
    "    hog_img=hog_image.reshape(-1)\n",
    "    return hog_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TinaCorporis', 'TineaCruris', 'TineaFaceii']\n"
     ]
    }
   ],
   "source": [
    "# obtaining training labels\n",
    "train_labels = os.listdir(train_path)\n",
    "\n",
    "# Train labels sorted\n",
    "train_labels.sort()\n",
    "print(train_labels)\n",
    "\n",
    "# Empty lists is used to hold feature vectors and labels\n",
    "hog_features = []\n",
    "labels = []\n",
    "i, j = 0, 0\n",
    "k = 0\n",
    "\n",
    "# Total number of images per class\n",
    "num_of_images = 107"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinaCorporis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rassh/anaconda3/lib/python3.6/site-packages/skimage/feature/_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed folder: TinaCorporis\n",
      "TineaCruris\n",
      "Processed folder: TineaCruris\n",
      "TineaFaceii\n",
      "Processed folder: TineaFaceii\n",
      "Feature Extracted\n"
     ]
    }
   ],
   "source": [
    "# loop over folders to exract features from each image in it.\n",
    "\n",
    "for training_name in train_labels:\n",
    "    # join the training data path and each species training folder\n",
    "    dir = os.path.join(train_path, training_name)\n",
    "    print(training_name)\n",
    "\n",
    "    # get the current training label\n",
    "    current_label = training_name\n",
    "\n",
    "    k = 1\n",
    "    # loop over the images in each sub-folder\n",
    "    for x in range(1,108):\n",
    "        # get the image file name\n",
    "        file = dir + \"/\" + str(x) + \".JPG\"\n",
    "\n",
    "        # read the image and resize it to a fixed-size\n",
    "        image = cv2.imread(file)\n",
    "        image = cv2.resize(image, fixed_size)\n",
    "        \n",
    "        # HOG function is call to extract each feature image\n",
    "        res1 = hog_ext(image)\n",
    "        \n",
    "        # concating features\n",
    "        hog_feature = np.hstack([res1])\n",
    "\n",
    "        # update the list of labels and feature vectors\n",
    "        labels.append(current_label)\n",
    "        hog_features.append(hog_feature)\n",
    "\n",
    "        i += 1\n",
    "        k += 1\n",
    "    print (\"Processed folder: {}\".format(current_label))\n",
    "    j += 1\n",
    "\n",
    "print (\"Feature Extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector size (321, 62500)\n",
      "Training Labels (321,)\n",
      "Training labels encoded...\n"
     ]
    }
   ],
   "source": [
    "# get the overall feature vector size\n",
    "print (\"Feature vector size {}\".format(np.array(hog_features).shape))\n",
    "\n",
    "# get the overall training label size\n",
    "print (\"Training Labels {}\".format(np.array(labels).shape))\n",
    "\n",
    "# encode the target labels\n",
    "targetNames = np.unique(labels)\n",
    "le = LabelEncoder()\n",
    "target = le.fit_transform(labels)\n",
    "print (\"Training labels encoded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] feature vector normalized...\n",
      "[STATUS] target labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[STATUS] target labels shape: (321,)\n"
     ]
    }
   ],
   "source": [
    "# normalize the feature vector in the range (0-1)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaled_features = scaler.fit_transform(hog_features)\n",
    "print (\"[STATUS] feature vector normalized...\")\n",
    "\n",
    "print (\"[STATUS] target labels: {}\".format(target))\n",
    "print (\"[STATUS] target labels shape: {}\".format(target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING ENDED\n"
     ]
    }
   ],
   "source": [
    "# save the feature vector using HDF5\n",
    "h5f_data = h5py.File('output/data.h5', 'w')\n",
    "h5f_data.create_dataset('dataset_1', data=np.array(rescaled_features))\n",
    "\n",
    "h5f_label = h5py.File('output/labels.h5', 'w')\n",
    "h5f_label.create_dataset('dataset_1', data=np.array(target))\n",
    "\n",
    "h5f_data.close()\n",
    "h5f_label.close()\n",
    "\n",
    "print (\"TRAINING ENDED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
